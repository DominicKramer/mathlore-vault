ProtoResult:
. "{\bf (Law of Large Numbers)} Let $X_1$, $X_2$, $\dots$, 
   $X_n$ be an independent trials process, with finite expected
   value $\mu = E(X_j)$ and finite variance $\sigma^2 = 
   V(X_j)$. Let $S_n = X_1 + X_2 +\cdots+ X_n$. Then for any 
   $\epsilon > 0$, $$ P ( | \frac {S_n}n - \mu | \geq \epsilon 
   ) \to 0 $$ as $n arrow \infty$. Equivalently, $$ P ( | \frac
   {S_n}n - \mu | < \epsilon ) \to 1 $$ as $n arrow \infty$. 
   .2in {\bf Proof.\ } Since $X_1$, $X_2$, $\dots$, $X_n$ are 
   independent and have the same distributions, we can apply 
   Theorem 6.9}. We obtain $$ V(S_n) = n\sigma^2\ , $$ and $$ V
   (\frac {S_n}n) = \frac {\sigma^2}n\ . $$ Also we know that 
   $$ E (\frac {S_n}n) = \mu\ . $$ By Chebyshev's Inequality, 
   for any $\epsilon > 0$, $$ P ( | \frac {S_n}n - \mu | \geq 
   \epsilon ) \leq \frac {\sigma^2}{n\epsilon^2}\ . $$ Thus, 
   for fixed $\epsilon$, $$ P ( | \frac {S_n}n - \mu | \geq 
   \epsilon ) \to 0 $$ as $n arrow \infty$, or equivalently, $$
   P ( | \frac {S_n n - \mu | < \epsilon ) \to 1 $$ as $n arrow
   \infty$."
Metadata:
. reference:
  . source: "@IntroductionToProbability"
    page: "308"
    offset: "318"
. id: "5e2fc0a764735772ef984c7a"

