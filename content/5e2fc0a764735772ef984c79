ProtoResult:
. "{\bf (Chebyshev Inequality)} Let $X$ be a discrete random 
   variable with expected value $\mu = E(X)$, and let $\epsilon
   > 0$ be any positive real number. Then $$ P(|X - \mu| \geq 
   \epsilon) \leq \frac {V(X)}{\epsilon^2}\ . $$ .2in {\bf 
   Proof.\ } Let $m(x)$ denote the distribution function of 
   $X$. Then the probability that $X$ differs from $\mu$ by at 
   least $\epsilon$ is given by $$P(|X - \mu| \geq \epsilon) = 
   \sum_{|x - \mu| \geq \epsilon} m(x)\ $$ We know that $$V(X) 
   = \sum_x (x - \mu)^2 m(x)\ $$ and this is clearly at least 
   as large as $$\sum_{|x - \mu| \geq \epsilon} (x - \mu)^2 
   m(x)\ $$ since all the summands are positive and we have 
   restricted the range of summation in the second sum. But 
   this last sum is at least $$ \sum_{|x - \mu| \geq \epsilon} 
   \epsilon^2 m(x) &=& \epsilon^2 \sum_{|x - \mu| \geq 
   \epsilon} m(x) \\ &=& \epsilon^2 P(|X - \mu| \geq \epsilon)\
   .\\ $$ So, $$ P(|X - \mu| \geq \epsilon) \leq \frac 
   {V(X)}{\epsilon^2}\ . $$"
Metadata:
. reference:
  . source: "@IntroductionToProbability"
    page: "307"
    offset: "317"
. id: "5e2fc0a764735772ef984c79"

