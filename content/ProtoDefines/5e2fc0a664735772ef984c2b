ProtoDefines:
. "A Markov chain is called an {ergodic\/} chain if it is 
   possible to go from every state to every state (not 
   necessarily in one move)."
Metadata:
. reference:
  . source: "@IntroductionToProbability"
    page: "435"
    offset: "445"
. id: "5e2fc0a664735772ef984c2b"

