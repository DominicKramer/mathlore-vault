ProtoDefines:
. "A state $s_i$ of a Markov chain is called {absorbing\/} if 
   it is impossible to leave it (i.e., $p_{ii} = 1$). A Markov 
   chain is {absorbing\/} if it has at least one absorbing 
   state, and if from every state it is possible to go to an 
   absorbing state (not necessarily in one step)."
Metadata:
. reference:
  . source: "@IntroductionToProbability"
    page: "418"
    offset: "428"
. id: "5e2fc0a764735772ef984c65"

