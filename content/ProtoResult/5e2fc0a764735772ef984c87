ProtoResult:
. "Suppose $X$ is a continuous random variable with range 
   contained in the interval $[-M,M]$. Then the series $$ g(t) 
   = \sum_{k = 0}^\infty \frac{\mu_k t^k}{k!} $$ converges for 
   all $t$ to an infinitely differentiable function $g(t)$, and
   $g^{(n)}(0) = \mu_n$. .2in {\bf Proof.\ } We have $$ \mu_k =
   \int_{-M}^{+M} x^k f_X(x) dx\ , $$ so $$ |\mu_k| &\leq& 
   \int_{-M}^{+M} |x|^k f_X(x) dx \\ &\leq& M^k \int_{-M}^{+M} 
   f_X(x) dx = M^k\ . $$ Hence, for all $N$ we have $$ \sum_{k 
   = 0}^N |\frac{\mu_k t^k}{k!} | \leq \sum_{k = 0}^N 
   \frac{(M|t|)^k}{k!} \leq e^{M|t|}\ , $$ which shows that the
   power series converges for all $t$. We know that the sum of 
   a convergent power series is always differentiable."
Metadata:
. reference:
  . source: "@IntroductionToProbability"
    page: "398"
    offset: "408"
. id: "5e2fc0a764735772ef984c87"

